{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Input Vars]\n",
    "#   1. <string> PATH_TO_DESIRED_LOCATION: It should be the directory containing (1) images/ (2) train.txt (3) test.txt (4) val.txt\n",
    "\n",
    "# [Output Vars]\n",
    "#   1. <ndarray> np_train_txt: It contains both the directory to a specific image and the related label.\n",
    "#   2. <ndarray> np_test_txt: It contains both the directory to a specific image and the related label.\n",
    "#   3. <ndarray> np_val_txt: It contains both the directory to a specific image and the related label.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def read_metadata_files(Root_Path):\n",
    "    # train.txt\n",
    "    train_txt = pd.read_csv(Root_Path+\"train.txt\", sep=\" \")\n",
    "    NP_TRAIN_TXT = np.array(train_txt)\n",
    "    \n",
    "    # test.txt\n",
    "    test_txt = pd.read_csv(Root_Path+\"test.txt\", sep=\" \")\n",
    "    NP_TEST_TXT = np.array(test_txt)\n",
    "    \n",
    "    # val.txt\n",
    "    val_txt = pd.read_csv(Root_Path+\"val.txt\", sep=\" \")\n",
    "    NP_VAL_TXT = np.array(val_txt)\n",
    "    \n",
    "    print(f\"[Check] There are {NP_TRAIN_TXT.shape[0]} pairs in train.txt.\")\n",
    "    print(f\"[Check] There are {NP_TEST_TXT.shape[0]} pairs in test.txt.\")\n",
    "    print(f\"[Check] There are {NP_VAL_TXT.shape[0]} pairs in val.txt.\\n\")\n",
    "    \n",
    "    return NP_TRAIN_TXT, NP_TEST_TXT, NP_VAL_TXT, len(NP_TRAIN_TXT), len(NP_TEST_TXT), len(NP_VAL_TXT)\n",
    "\n",
    "Root_Path = \"C:/Users/USER/Desktop/Projects/Github_Repo/AI/DeepLearning/__HW1_DATA/\"\n",
    "train_meta, test_meta, val_meta, len_train_meta, len_test_meta, len_val_meta = read_metadata_files(Root_Path)\n",
    "print(f\"The shape of test_meta is {test_meta.shape}\")\n",
    "print(f\"The path of 1st example in test_meta is {test_meta[0][0]}\")\n",
    "print(f\"The label of 1st example in test_meta is {test_meta[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "#len_dataset = len_test_meta\n",
    "#dataset = test_meta\n",
    "#(height, width) = (28, 28)\n",
    "\n",
    "def load_dataset(len_dataset, dataset, height, width):\n",
    "    img_dataset = np.zeros((len_dataset, height, width, 3))\n",
    "    img_label = np.zeros(len_dataset)\n",
    "\n",
    "    for i in tqdm(range(len_dataset)):\n",
    "        # 取 label\n",
    "        img_label[i] = int(dataset[i][1])\n",
    "        # 取 input\n",
    "        img = cv.imread(Root_Path + dataset[i][0])\n",
    "        img_resize = cv.resize(img, (height, width))\n",
    "        \n",
    "    \n",
    "        # 把 img 放入 dataset\n",
    "        img_dataset[i] = img_resize/255.\n",
    "    return img_dataset, img_label\n",
    "\n",
    "# read the dataset with load func\n",
    "\n",
    "train_image_2, train_label_2 = load_dataset(len_train_meta, train_meta, 32, 32)\n",
    "test_image_2, test_label_2 = load_dataset(len_test_meta, test_meta, 32, 32)\n",
    "val_image_2, val_label_2 = load_dataset(len_val_meta, val_meta, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Simple Convolutional Neural Network with Keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, 5,input_shape=(28,28,1), padding=\"same\", activation='sigmoid') )\n",
    "model.add(layers.AvgPool2D(2,2))\n",
    "model.add(layers.Conv2D(16, 5, padding=\"valid\", activation=\"sigmoid\"))\n",
    "model.add(layers.AvgPool2D(2,2))\n",
    "model.add(layers.Conv2D(120, 5, padding=\"valid\", activation=\"sigmoid\"))\n",
    "model.add(layers.Flatten()) # expected 120\n",
    "model.add(layers.Dense(84, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kx_train = x_train.reshape(len(x_train),28,28,1)\n",
    "kx_test = x_test.reshape(len(x_test),28,28,1)\n",
    "kx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(kx_train, y_train, validation_data=(kx_test,y_test), batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history, miny=None):\n",
    "    acc = history.history['acc']\n",
    "    test_acc = history.history['val_acc']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, test_acc)\n",
    "    if miny:\n",
    "        plt.ylim(miny, 1.0)\n",
    "    plt.title('accuracy') \n",
    "    plt.figure()\n",
    "    \n",
    "plot_accuracy(history, miny=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(kx_test)\n",
    "pred_digits = np.argmax(preds, axis=1)\n",
    "y_digits = np.argmax(y_test, axis=1)\n",
    "print(pred_digits)\n",
    "print(y_digits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
