{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOI Classification using (A) LeNet5, (B) AlexNet, (C) ResNet\n",
    "\n",
    "## Outline:\n",
    "* Step 01: Get a feel of data, draw it.\n",
    "* Step 02: Define dataset class.\n",
    "--------------------------------\n",
    "* Step A1: Define LeNet5.\n",
    "* Step A2: Setup dataloader for LeNet5.\n",
    "* Step A3: Setup loss and hyper parameter for LeNet5.\n",
    "* Step A4: Train LeNet5.\n",
    "* Step A5: Evaluate the performance of LeNet5.\n",
    "* Step A6: Test LeNet5.\n",
    "--------------------------------\n",
    "* Step B1: Define AlexNet.\n",
    "* Step B2: Setup dataloader for AlexNet5.\n",
    "* Step B3: Setup loss and hyper parameter for AlexNet5.\n",
    "* Step B4: Train AlexNet5.\n",
    "* Step B5: Evaluate the performance of AlexNet5.\n",
    "* Step B6: Test AlexNet5.\n",
    "--------------------------------\n",
    "* Step C1: Define ResNet18.\n",
    "* Step C2: Setup dataloader for ResNet18.\n",
    "* Step C3: Setup loss and hyper parameter for ResNet18.\n",
    "* Step C4: Train ResNet18.\n",
    "* Step C5: Evaluate the performance of ResNet18.\n",
    "* Step C6: Test ResNet18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01: Get a feel of data, draw it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv # for reading image data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_table = {\n",
    "    0: \"normal\",\n",
    "    1: \"void\",\n",
    "    2: \"Horizontal Defect\",\n",
    "    3: \"Vertical Defect\",\n",
    "    4: \"Edge Defect\",\n",
    "    5: \"Partical\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_train = \"../__HW5_DATA/train_images/\"\n",
    "root_test = \"../__HW5_DATA/test_images/\"\n",
    "train_csv = \"../__HW5_DATA/train.csv\"\n",
    "test_csv = \"../__HW5_DATA/test.csv\"\n",
    "df_train = pd.read_csv(train_csv)\n",
    "\n",
    "id = 4\n",
    "png_img = cv.imread(root_train + df_train.ID[id])\n",
    "label = df_train.Label[id]\n",
    "print(f\"[Label] => {df_train.Label[id]}; [Label Actually Means] => {label_map_table[label]}\")\n",
    "plt.imshow(png_img)\n",
    "plt.show()\n",
    "\n",
    "print(png_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02: Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "\n",
    "# [Input Args]\n",
    "# 1. target_csv <string>: It's the metadata file describe the name of image and its label.\n",
    "# 2. root_path  <string>: It's the path to the image folder. Combination of this and name is the full path to the image.\n",
    "# 3. height <int>: Use this for elastically resize image to desired shape.\n",
    "# 4. width <int>: Use this for elastically resize image to desired shape.\n",
    "class AOI_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, target_csv, root_path, height, width):\n",
    "        \n",
    "        # height, width\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # register self\n",
    "        self.target_csv = target_csv\n",
    "        self.root_path = root_path\n",
    "        \n",
    "        # 1. Read CSV file through root_path\n",
    "        self.df = pd.read_csv(self.target_csv)\n",
    "        \n",
    "        # 2. Remember the length\n",
    "        self.count = len(self.df)\n",
    "        \n",
    "        # 3. to tensor\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Read images\n",
    "        img = cv.imread(self.root_path + self.df.ID[index])\n",
    "        \n",
    "        # Add here at LeNet-like Model v3\n",
    "        #img_normalize = img / 255.\n",
    "        # Change here at AlexNet-link Model v1\n",
    "        img_normalize = cv.resize(img, (self.height, self.width))/255.0\n",
    "\n",
    "        # To Tensor\n",
    "        img_tensor = self.to_tensor(img)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.df.Label[index]\n",
    "        \n",
    "        return (img_tensor, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A1: Define LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d( 3,  6, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d( 6, 16, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(16, 50, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(50 * 64 * 64, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 50 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x)\n",
    "        return x\n",
    "    \n",
    "lenet = LeNet()\n",
    "print(lenet.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A2: Setup dataloader for LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "\n",
    "if torch.cuda.is_available(): summary(lenet, (3, height, width))\n",
    "Train_Dataset = AOI_Dataset(target_csv = train_csv, root_path = root_train, height = height, width = width)\n",
    "\n",
    "batch_size = 8\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 43\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(Train_Dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "Train_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "Val_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A3: Setup loss and hyper parameter for LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(lenet.parameters(), lr=1e-4)\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A4: Train LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "print_probe_num = 100\n",
    "for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Train_DataLoader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) # GPU        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = lenet(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_probe_num == (print_probe_num - 1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / print_probe_num))\n",
    "            loss_list.append(running_loss / print_probe_num)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Train\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Train_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = lenet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        train_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "  \n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Train\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Val_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = lenet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        val_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "toc = time.time()\n",
    "print(f\"Spend {round(toc - tic, 2)} (sec)\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A5: Evaluate the performance of LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.title(\"LeNet5: Accuracy Curve\", fontsize = 24)\n",
    "plt.xlabel(\"Epochs\"    , fontsize = 20)\n",
    "plt.ylabel(\"Accuracy %\", fontsize = 20)\n",
    "plt.plot(train_acc_list, label = \"train acc.\")\n",
    "plt.plot(val_acc_list  , label = \"val acc.\")\n",
    "plt.legend(loc = 2, fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "## Loss\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"LeNet5: Loss Curve\", fontsize = 24)\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Probes\", fontsize = 20)\n",
    "plt.ylabel(\"Loss\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A6: Test LeNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Dataset = AOI_Dataset(target_csv = test_csv, root_path = root_test, height = height, width = width)\n",
    "Test_DataLoader = torch.utils.data.DataLoader(dataset = Test_Dataset, batch_size = 1, shuffle = False)\n",
    "Name_of_csv_file = \"test01_0519.csv\"\n",
    "\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_test_np = df_test.to_numpy()\n",
    "\n",
    "count = -1\n",
    "with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    for datum in tqdm(Test_DataLoader):\n",
    "        count = count + 1\n",
    "        imgs = datum[0].to(device)\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = lenet(imgs.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        df_test_np[count][1] = float(preds)\n",
    "        \n",
    "df = pd.DataFrame(df_test_np, columns = ['ID','Label'])\n",
    "df.to_csv(Name_of_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B1: Define AlexNet.\n",
    "* Get the AlexNet from the link below.\n",
    "* github ref link: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int = 6) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "alexnet = AlexNet()\n",
    "print(alexnet.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B2: Setup dataloader for AlexNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "\n",
    "height = 256\n",
    "width = 256\n",
    "\n",
    "if torch.cuda.is_available(): summary(alexnet, (3, height, width))\n",
    "Train_Dataset = AOI_Dataset(target_csv = train_csv, root_path = root_train, width=width, height=height)\n",
    "\n",
    "batch_size = 8\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 43\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(Train_Dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "Train_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "Val_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B3: Setup loss and hyper parameter for AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(alexnet.parameters(), lr=1e-4)\n",
    "epoch = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B4: Train AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "print_probe_num = 100\n",
    "for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Train_DataLoader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) # GPU        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = alexnet(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_probe_num == (print_probe_num - 1):\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / print_probe_num))\n",
    "            loss_list.append(running_loss / print_probe_num)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Train\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Train_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = alexnet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        train_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Acc\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Val_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = alexnet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        val_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "toc = time.time()\n",
    "print(f\"Spend {round(toc - tic, 2)} (sec)\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B5: Evaluate the performance of AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.title(\"AlexNet: Accuracy Curve\", fontsize = 24)\n",
    "plt.xlabel(\"Epochs\"    , fontsize = 20)\n",
    "plt.ylabel(\"Accuracy %\", fontsize = 20)\n",
    "plt.plot(train_acc_list, label = \"train acc.\")\n",
    "plt.plot(val_acc_list  , label = \"val acc.\")\n",
    "plt.legend(loc = 2, fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "## Loss\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"AlexNet: Loss Curve\", fontsize = 24)\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Probes\", fontsize = 20)\n",
    "plt.ylabel(\"Loss\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B6: Test AlexNet5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Dataset = AOI_Dataset(target_csv = test_csv, root_path = root_test, height = height , width = width)\n",
    "Test_DataLoader = torch.utils.data.DataLoader(dataset = Test_Dataset, batch_size = 1, shuffle = False)\n",
    "Name_of_csv_file = \"test01_0519.csv\"\n",
    "\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_test_np = df_test.to_numpy()\n",
    "\n",
    "count = -1\n",
    "with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    for datum in tqdm(Test_DataLoader):\n",
    "        count = count + 1\n",
    "        imgs = datum[0].to(device)\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = alexnet(imgs.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        df_test_np[count][1] = float(preds)\n",
    "        \n",
    "df = pd.DataFrame(df_test_np, columns = ['ID','Label'])\n",
    "df.to_csv(Name_of_csv_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1: Define ResNet18.\n",
    "* Get the ResNet18 from the link below.\n",
    "* medium ref link: https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
    "\n",
    "def activation_func(activation):\n",
    "    return  nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    \n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "    \n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))\n",
    "\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    \"\"\"\n",
    "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )\n",
    "\n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "class ResNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet layer composed by `n` blocks stacked one after the other\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x\n",
    "    \n",
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet encoder composed by layers with increasing features.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation='relu', block=ResNetBasicBlock, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation_func(activation),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,*args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "    \n",
    "class ResnetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "def resnet18(in_channels, n_classes, block=ResNetBasicBlock, *args, **kwargs):\n",
    "    return ResNet(in_channels, n_classes, block=block, deepths=[2, 2, 2, 2], *args, **kwargs)\n",
    "\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "resnet = resnet18(3, 6)\n",
    "print(resnet.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C2: Setup dataloader for ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "\n",
    "height = 256\n",
    "width = 256\n",
    "\n",
    "if torch.cuda.is_available(): summary(resnet, (3, height, width))\n",
    "Train_Dataset = AOI_Dataset(target_csv = train_csv, root_path = root_train, width = width, height = height)\n",
    "\n",
    "batch_size = 8\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 43\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(Train_Dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "Train_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size = batch_size, sampler = train_sampler)\n",
    "Val_DataLoader = torch.utils.data.DataLoader(Train_Dataset, batch_size = batch_size, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C3: Setup loss and hyper parameter for ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(resnet.parameters(), lr=1e-4)\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C4: Train ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "print_probe_num = 100\n",
    "\n",
    "for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Train_DataLoader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) # GPU        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_probe_num == (print_probe_num - 1):\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / print_probe_num))\n",
    "            loss_list.append(running_loss / print_probe_num)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Train\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Train_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = resnet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        train_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Val\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        for datum in tqdm(Val_DataLoader):\n",
    "\n",
    "            imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = resnet(imgs.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labs.size(0)\n",
    "            correct += (preds == labs).sum().item()\n",
    "        val_acc_list.append(float(correct)/float(total))\n",
    "        print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "        \n",
    "toc = time.time()\n",
    "print(f\"Spend {round(toc - tic, 2)} (sec)\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C5: Evaluate the performance of ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.title(\"ResNet18: Accuracy Curve\", fontsize = 24)\n",
    "plt.xlabel(\"Epochs\"    , fontsize = 20)\n",
    "plt.ylabel(\"Accuracy %\", fontsize = 20)\n",
    "plt.plot(train_acc_list, label = \"train acc.\")\n",
    "plt.plot(val_acc_list  , label = \"val acc.\")\n",
    "plt.legend(loc = 2, fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "## Loss\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"ResNet18: Loss Curve\", fontsize = 24)\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Probes\", fontsize = 20)\n",
    "plt.ylabel(\"Loss\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step C6: Test ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Dataset = AOI_Dataset(target_csv = test_csv, root_path = root_test, width = width, height = height)\n",
    "Test_DataLoader = torch.utils.data.DataLoader(dataset = Test_Dataset, batch_size = 1, shuffle = False)\n",
    "Name_of_csv_file = \"test01_0519.csv\"\n",
    "\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_test_np = df_test.to_numpy()\n",
    "\n",
    "count = -1\n",
    "with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    for datum in tqdm(Test_DataLoader):\n",
    "        count = count + 1\n",
    "        imgs = datum[0].to(device)\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = resnet(imgs.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        print(preds)\n",
    "        df_test_np[count][1] = float(preds)\n",
    "        \n",
    "df = pd.DataFrame(df_test_np, columns = ['ID','Label'])\n",
    "df.to_csv(Name_of_csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
