{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1d975d",
   "metadata": {},
   "source": [
    "* [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "* [Do not need softmax](https://stackoverflow.com/questions/55675345/should-i-use-softmax-as-output-when-using-cross-entropy-loss-in-pytorch)\n",
    "* I learned how to implement LeNet5\n",
    "* I learned how to train net on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930870cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to plot my  diagram inside the cell.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34726b5",
   "metadata": {},
   "source": [
    "## My Customized Dataset Class\n",
    "In order to implement this section, I read two very good references:\n",
    "* [WRITING CUSTOM DATASETS, DATALOADERS AND TRANSFORMS](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
    "* [utkuozbulak/pytorch-custom-dataset-examples](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3ced8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, root_path, subset, height, width):\n",
    "        \n",
    "        # Need it in __getitem__() to transform numpy array to tensor.\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        # Read CSV Metadata and convert it to numpy format\n",
    "        subset_txt = pd.read_csv(root_path + subset, sep=\" \")\n",
    "        self.np_subset_txt = np.array(subset_txt)\n",
    "        \n",
    "        # Need it in __len__()\n",
    "        self.count = len(self.np_subset_txt)\n",
    "        \n",
    "        # Need it in __getitem__() to resize image to desired size\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get Label\n",
    "        label = int(self.np_subset_txt[index][1])\n",
    "        \n",
    "        # Get Image\n",
    "        img = cv.imread(root_path + self.np_subset_txt[index][0])\n",
    "        img_resize = cv.resize(img, (self.height, self.width))/255.0\n",
    "        img_resize = img_resize.reshape(-1, self.height, self.width) # to make channel first\n",
    "        img_resize_tensor = self.to_tensor(img_resize)\n",
    "        return (img_resize, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bc7a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:/Users/USER/Desktop/Projects/Github_Repo/AI/DeepLearning/__HW1_DATA/\"\n",
    "height = 30\n",
    "width = 30\n",
    "\n",
    "Train_Dataset = AnimalDataset(root_path = root_path, subset = \"train.txt\", height = height, width = width)\n",
    "Test_Dataset = AnimalDataset(root_path = root_path, subset = \"test.txt\", height = height, width = width)\n",
    "Val_Dataset = AnimalDataset(root_path = root_path, subset = \"val.txt\", height = height, width = width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0ec18",
   "metadata": {},
   "source": [
    "## Define My DataLoader r.s.t. AnimalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f44965e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "shuffle = True\n",
    "\n",
    "Train_DataLoader = torch.utils.data.DataLoader(dataset=Train_Dataset, batch_size = batch_size, shuffle=shuffle)\n",
    "Test_DataLoader = torch.utils.data.DataLoader(dataset=Test_Dataset, batch_size = batch_size, shuffle=shuffle)\n",
    "Val_DataLoader = torch.utils.data.DataLoader(dataset=Val_Dataset, batch_size = batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7886b41",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network(Use GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e309610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 50)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x)\n",
    "        return x\n",
    "    \n",
    "lenet = LeNet()\n",
    "lenet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd5bb9",
   "metadata": {},
   "source": [
    "## Define a loss function and Set up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6315f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(lenet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52c035",
   "metadata": {},
   "source": [
    "## Train the network on the training data\n",
    "# How to use validation dataset\n",
    "# Try to implement it as a function to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c83e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/1267 [00:00<02:45,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 3.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████▊              | 1036/1267 [02:08<00:27,  8.45it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Train_DataLoader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) # GPU\n",
    "        #inputs, labels = data # CPU\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = lenet(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "                for datum in tqdm(Train_DataLoader):\n",
    "                    imgs, labs = datum[0].to(device), datum[1].to(device)\n",
    "                    # calculate outputs by running images through the network \n",
    "                    outputs = lenet(imgs.float())\n",
    "                    # the class with the highest energy is what we choose as prediction\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    total += labs.size(0)\n",
    "                    correct += (preds == labs).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eeb348",
   "metadata": {},
   "source": [
    "## Save the model for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cfda673",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './LeNet.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a22d2a",
   "metadata": {},
   "source": [
    "## Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd5de62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 2 %\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "lenet.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    for data in Test_DataLoader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = lenet(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f061c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 20, 48, 41,  5, 33, 34,  0, 49, 22, 34, 34,  0, 33, 36, 46, 20, 45,\n",
      "         3, 24, 48, 45, 36, 33, 45, 40, 49, 28, 46, 46,  1,  2, 48, 40, 41, 38,\n",
      "        36, 44,  5,  8, 23, 38, 40, 23,  8, 25, 20, 34, 33, 40])\n",
      "tensor([ 0, 20, 22, 25, 40,  6, 40,  5,  3, 42, 42, 34,  6, 32, 28, 39, 24, 18,\n",
      "         7, 35, 38, 46, 20, 20, 45, 30, 46,  2, 49,  0, 11, 27, 13, 29, 39, 19,\n",
      "        44, 38, 25, 32, 33, 35, 40, 23,  7, 10, 42, 49, 33, 19])\n",
      "tensor([49, 41, 33, 44, 34, 14,  3, 36, 46, 49, 39, 35,  2, 11, 48, 40, 44, 49,\n",
      "        48, 34,  3, 15, 38, 23, 38,  5, 34, 44, 25, 45,  0, 44,  7, 44,  2, 33,\n",
      "        46,  4, 40, 20, 33, 19, 34, 28, 37, 38, 40, 33, 44, 15])\n",
      "tensor([46, 17, 22, 27, 21, 13,  7, 33, 46, 24,  8, 17, 27,  5, 48,  6, 49, 47,\n",
      "        48,  8, 27,  3, 40, 31, 37, 21, 30,  6, 44, 45, 45, 11, 28, 49, 44, 23,\n",
      "        42,  4, 23, 42, 18, 22, 35, 26, 26, 10, 16, 25, 34, 16])\n",
      "tensor([14, 23, 14, 48, 33, 44, 23, 45, 16, 23, 40, 39, 28, 34, 34,  2,  6, 33,\n",
      "        28, 41, 49,  2, 14, 44, 34,  2, 23, 48, 33, 34, 14, 33, 29,  5, 27, 47,\n",
      "        33, 33, 20, 14,  2, 15, 35, 41,  0, 33,  4,  2, 25, 16])\n",
      "tensor([30, 23, 37, 48,  2,  9, 14,  4, 36,  8, 16, 41, 26, 15, 12, 10,  9, 43,\n",
      "        10, 39, 35, 14, 10, 34,  6,  9, 27, 48, 14, 32,  1, 17,  4, 34, 14, 20,\n",
      "         8, 33, 42, 33, 28, 31, 15, 27, 11, 31,  2, 16, 30, 16])\n",
      "tensor([48, 40, 41,  5,  3,  5, 14, 48, 35, 20, 27, 34, 48, 45, 34, 25, 39, 34,\n",
      "        38, 14, 27, 44, 32, 48,  0, 33, 41,  0,  0, 44, 44, 22, 33, 42,  4, 16,\n",
      "        20,  4,  0, 23, 22, 40, 32, 42, 20, 33, 33,  8, 41, 33])\n",
      "tensor([48, 28, 35, 38, 37, 25, 27, 12, 13, 18, 10, 11, 12, 35, 31,  5, 12,  7,\n",
      "         5,  1, 29, 11, 25,  0,  0, 33, 41, 39, 41, 12, 21, 45, 45, 38,  3, 18,\n",
      "        33,  7,  9, 27, 38,  2, 47, 29, 15, 16, 14, 40, 39,  6])\n",
      "tensor([ 3, 33, 48, 23, 23, 20, 48, 40, 44,  5,  4,  0, 22, 34, 25, 33, 41, 33,\n",
      "        17, 34, 34, 17,  0, 44, 24, 44,  0, 33, 22, 49, 41,  2, 40,  2, 39, 20,\n",
      "        40, 23, 46,  9, 48, 34, 48,  4, 44, 44, 33, 33, 35, 37])\n",
      "tensor([17,  8, 15, 35, 40, 30, 42, 26, 49, 19, 12,  4, 24, 26, 28, 14,  0, 37,\n",
      "         5, 15, 32,  3, 41,  6, 32,  4, 28, 43, 35, 44, 26, 10,  5,  1, 36, 19,\n",
      "        31,  3, 39, 43, 18, 14, 39,  6,  3, 45, 36, 36, 43,  4])\n",
      "tensor([14, 40, 28, 16, 44, 23, 18, 48, 23, 48,  2, 20, 48, 32, 15, 27, 38, 19,\n",
      "        33, 16, 40, 40, 23,  0, 34, 22, 34,  0, 44,  4, 27, 34,  4, 33, 41, 15,\n",
      "        34, 34, 39, 44, 22, 38, 40,  0, 40, 47, 33,  2, 33, 19])\n",
      "tensor([ 1, 24,  8, 26, 29, 10, 18, 45, 30, 47, 20, 43,  7, 42, 37,  9, 44, 19,\n",
      "        21, 47, 49, 19, 10,  6, 24, 24, 36,  5, 11, 28, 29, 21, 12,  7, 32, 13,\n",
      "        21, 36, 39,  5, 38, 22, 13, 41, 13, 49, 43, 31, 34, 33])\n",
      "tensor([ 8, 40, 34, 20, 38, 40, 14, 36, 29, 27,  2,  5, 36, 33, 44,  2,  2, 36,\n",
      "        32, 46, 33, 11,  0, 19, 27, 33,  4, 25, 20, 36, 44, 32, 20, 40, 49, 34,\n",
      "         0, 25, 20, 34, 24,  0, 25, 20, 39, 44, 48, 27,  0, 36])\n",
      "tensor([23,  2, 25, 18, 30, 32, 18, 16,  8, 27, 40, 31, 47, 21, 12,  9, 40, 24,\n",
      "        17, 46,  3,  2, 44, 16,  8, 25, 17, 11, 26, 34, 41, 32, 20, 34, 47, 49,\n",
      "         4, 11, 25, 22, 15, 46,  8, 20, 46, 49, 48, 23,  0, 37])\n",
      "tensor([27, 48, 16,  0, 39, 20, 14, 28,  2, 34, 16, 44, 20, 38, 22, 18, 20, 40,\n",
      "        34, 44, 34, 27,  2, 39, 36, 34,  2, 33, 25, 22, 38, 46, 34, 48, 45, 14,\n",
      "        48, 44,  4, 37, 27,  2, 45, 28, 35, 43, 40, 28, 20, 13])\n",
      "tensor([30, 12, 17,  0, 48, 15, 45,  1, 41, 26, 36, 19, 22,  4, 19, 23, 14, 33,\n",
      "        15, 44, 34,  1,  1, 44, 31, 24,  1, 17, 28, 22, 31, 46, 43, 45, 20, 17,\n",
      "        48, 38,  3, 22, 13, 28, 43,  9, 35, 29, 22,  3, 13, 43])\n",
      "tensor([33, 39, 15, 14, 40, 34, 46, 10,  2, 20, 15,  0, 41, 35, 45, 44, 38, 14,\n",
      "        22, 33, 27, 27, 48, 19, 40, 40, 33, 44, 23, 34,  2, 40, 41, 13, 38, 33,\n",
      "        23, 36, 25,  2, 22,  9, 33, 33,  4, 29,  2, 20, 44])\n",
      "tensor([ 2, 41, 37, 34, 29,  7, 19, 21, 36, 42, 48, 25, 39, 37, 18, 24,  0, 40,\n",
      "        37, 32,  7, 14, 47, 16, 41,  2, 47, 44, 23,  2, 20, 23, 46, 29, 38,  5,\n",
      "        15,  4, 38, 11, 13, 21, 36,  1, 30, 29,  9,  9, 47])\n",
      "Accuracy of the network on the test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "lenet.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in Val_DataLoader:\n",
    "        #print(labels)\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = net(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "58c33e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1267/1267 [03:16<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lenet = LeNet()\n",
    "lenet.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(Test_DataLoader):\n",
    "        #print(labels)\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = net(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #print(predicted)\n",
    "        #print(labels)\n",
    "        #break\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f106a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
