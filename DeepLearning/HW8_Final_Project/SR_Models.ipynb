{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Define Evaluation Metrics\n",
    "* PSNR\n",
    "* SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_img(input_array):\n",
    "    input_img = input_array[0]\n",
    "    input_img = input_img.transpose((1, 2, 0))\n",
    "    plt.imshow(input_img)\n",
    "    plt.show()\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean( (original/255. - compressed/255.) ** 2 )\n",
    "    if mse < 1.0e-10: return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "def calculate_PSNR(original_batch, compressed_batch, batch_size):\n",
    "    PSNR_TOTAL = 0\n",
    "    for num in range(batch_size):\n",
    "        psnr = PSNR(original_batch[num], compressed_batch[num])\n",
    "        PSNR_TOTAL = PSNR_TOTAL + psnr\n",
    "    return PSNR_TOTAL\n",
    "\n",
    "def SSIM(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_SSIM(img1, img2):\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Design Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DIV2K_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, width, height, scale, path_to_imgs, transform = None):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.scale = scale\n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.length = len(os.listdir(path_to_imgs))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Interpolation: INTER_CUBIC, INTER_NEAREST, INTER_LINEAR, INTER_LANCZOS4, 【INTER_AREA】\n",
    "        img = cv.imread(self.path_to_imgs + os.listdir(self.path_to_imgs)[index])\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        h, w, c = img_rgb.shape\n",
    "        if (h > w):\n",
    "            img_rgb = img_rgb.transpose((1,0,2))\n",
    "        \n",
    "        img_hr = cv.resize(img_rgb, (self.width             , self.height             ), interpolation = cv.INTER_AREA)\n",
    "        img_lr = cv.resize(img_hr , (self.width //self.scale, self.height //self.scale), interpolation = cv.INTER_AREA)\n",
    "        img_lr = cv.resize(img_lr , (self.width             , self.height             ), interpolation = cv.INTER_AREA)\n",
    "        if self.transform:\n",
    "            img_lr_tensor = self.transform(img_lr)\n",
    "            img_hr_tensor = self.transform(img_hr)\n",
    "        \n",
    "        return (img_lr_tensor, img_hr_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Define Model ==> SRCNN\n",
    "* Github Repo Link: https://github.com/yjn870/SRCNN-pytorch\n",
    "* Difference:\n",
    "    1. Added the zero padding\n",
    "    2. Used the Adam instead of the SGD\n",
    "    3. Removed the weights initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels = 1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size = 9, padding = 9 // 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size = 5, padding = 5 // 2)\n",
    "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size = 5, padding = 5 // 2)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Summerize Model & Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "width, height = 540, 360\n",
    "scale = 8\n",
    "path_to_train_imgs = \"../__HW8_DATA/DIV2K_train_HR/\"\n",
    "path_to_valid_imgs = \"../__HW8_DATA/DIV2K_valid_HR/\"\n",
    "trans_train = transforms.Compose([transforms.ToTensor()])\n",
    "trans_valid = transforms.Compose([transforms.ToTensor()]) \n",
    "batch_size = 5\n",
    "\n",
    "Train_Dataset = DIV2K_Dataset(width = width, height = height, scale = scale, path_to_imgs = path_to_train_imgs, transform = trans_train)\n",
    "Train_Dataloader = DataLoader(Train_Dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "Valid_Dataset = DIV2K_Dataset(width = width, height = height, scale = scale, path_to_imgs = path_to_valid_imgs, transform = trans_valid)\n",
    "Valid_Dataloader = DataLoader(Valid_Dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "if False:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SRCNN(num_channels = 3)\n",
    "    model = model.to(device)\n",
    "    summary(model, input_size = (3, 720, 1080))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6: Set Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SRCNN(num_channels = 3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "probe_number =  80\n",
    "loss_list = []\n",
    "psnr_before_list = []\n",
    "psnr_after_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_psnr_before = 0\n",
    "    running_psnr_after = 0\n",
    "    inner_epoch_count = 0\n",
    "    train_total = 0\n",
    "    for data in tqdm(Train_Dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        preds = model(inputs).clamp(0.0, 1.0)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        psnr_before= calculate_PSNR(inputs.data.cpu().numpy(), labels.data.cpu().numpy(), batch_size)\n",
    "        psnr_after = calculate_PSNR( preds.data.cpu().numpy(), labels.data.cpu().numpy(), batch_size)\n",
    "        \n",
    "        running_loss = running_loss + loss.item()\n",
    "        running_psnr_before = running_psnr_before + psnr_before\n",
    "        running_psnr_after  = running_psnr_after  + psnr_after\n",
    "        \n",
    "        train_total = train_total + labels.size(0)\n",
    "        inner_epoch_count = inner_epoch_count + 1\n",
    "        if inner_epoch_count % probe_number == probe_number - 1:\n",
    "            for ele in [inputs.data.cpu().numpy(), preds.data.cpu().numpy(), labels.data.cpu().numpy()]:\n",
    "                plt_img(ele)\n",
    "            loss_list.append(running_loss/train_total)\n",
    "            psnr_before_list.append(running_psnr_before/train_total)\n",
    "            psnr_after_list.append(running_psnr_after/train_total)\n",
    "            print(f\"Before: {round(psnr_before/train_total, 4)}, After: {round(psnr_after/train_total, 4)}, Diff: {(round((psnr_after - psnr_before)/train_total, 4))}, Loss: {round(running_loss/train_total, 5)}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    valid_total = 0\n",
    "    for data in tqdm(Valid_Dataloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        valid_total = valid_total + labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        for ele in [inputs.data.cpu().numpy(), preds.data.cpu().numpy()]:\n",
    "            plt_img(ele)\n",
    "                  \n",
    "        psnr_before= calculate_PSNR(inputs.data.cpu().numpy(), labels.data.cpu().numpy(), batch_size)\n",
    "        psnr_after = calculate_PSNR( preds.data.cpu().numpy(), labels.data.cpu().numpy(), batch_size)\n",
    "        print(f\"Before: {round(psnr_before/valid_total, 4)}, After: {round(psnr_after/valid_total, 4)}, Diff: {round((psnr_after - psnr_before)/valid_total, 4)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
