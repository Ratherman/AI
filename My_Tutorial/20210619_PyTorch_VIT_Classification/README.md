# Visual Transformer
[Paper Link](https://arxiv.org/abs/2010.11929) An Image is Worth 16 x 16 Words: Transformers for Image Recognition at Scale.
[Github Link]() Not yet decided

# Paper Note:
<details>
<summary> Abstract </summary>

1. Alexey Dosovitskiy (Google Research, Grain Team)
2. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place.
3. We show that the reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks.
4. Pre-trained on large amounts of data first, and then transferred to small-size dataset.
</details>
<details>
<summary> Introduction </summary>

</details>
<details>
<summary> Related Work </summary>

</details>
<details>
<summary> Method </summary>

</details>
<details>
<summary> Experiments </summary>

</details>
<details>
<summary> Conclusion </summary>

</details>
<details>
<summary> Appendix: Multihead Self-attention </summary>

</details>
<details>
<summary> Appendix: Experiment Details </summary>

</details>
<details>
<summary> Appendix: Additional Results </summary>

</details>
<details>
<summary> Appendix: Additional Analyses </summary>

</details>

# Code Blocks & Explanations